# -*- coding: utf-8 -*-
"""MICCAI_SimSiam.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ubw95T4Jqdw0bjQdBY65a1Gl1DnJYUsZ

# Leveraging Contrastive Learning with SimSiam for the Classification of Primary and Secondary Liver Cancers

## Author: Ramtin Mojtahedi - MojtahediRamtin@Gmail.com
## Date: Summer 2023

---

### Brief Description:

This notebook explores the use of SimSiam, a Simple Siamese contrastive self-supervised learning approach, to enhance the classification of liver tumors. The study particularly focuses on limited availability of labeled CT scans of liver cancer and seeks to improve classification efficacy. Three baseline CNN-based classifiers (Inception, Xception, and ResNet152) are pretrained with two different loss functions: mean squared error (MSE) and cosine similarity (COS), and their performances are compared.

---

### Generating Images
"""

import os
import numpy as np
import nibabel as nib
from skimage.transform import resize
from skimage.measure import label as skimage_label, regionprops
from tqdm import tqdm
from skimage.segmentation import clear_border
import cv2
import re
import heapq
from sklearn.model_selection import train_test_split
import random

# Define the directories containing the images and labels for each tumor type
image_paths = {
    'HCC': '/mnt/largedrive0/rmojtahedi/liver_classifcation/images/HCC',
    'ICC': '/mnt/largedrive0/rmojtahedi/liver_classifcation/images/ICC',
    'MCRC': '/mnt/largedrive0/rmojtahedi/liver_classifcation/images/MCRC'
}

label_paths = {
    'HCC': '/mnt/largedrive0/rmojtahedi/liver_classifcation/labels/HCC',
    'ICC': '/mnt/largedrive0/rmojtahedi/liver_classifcation/labels/ICC',
    'MCRC': '/mnt/largedrive0/rmojtahedi/liver_classifcation/labels/MCRC'
}

# Define the directory where the tumor slices will be saved
output_dir = '/mnt/largedrive0/rmojtahedi/liver_classifcation/MICCAI_SIMSIAM/Extracted_Tumour_Images'

output_dirs = {
    'HCC': {
        'train': os.path.join(output_dir, 'HCC', 'train'),
        'val': os.path.join(output_dir, 'HCC', 'val')
    },
    'ICC': {
        'train': os.path.join(output_dir, 'ICC', 'train'),
        'val': os.path.join(output_dir, 'ICC', 'val')
    },
    'MCRC': {
        'train': os.path.join(output_dir, 'MCRC', 'train'),
        'val': os.path.join(output_dir, 'MCRC', 'val')
    }
}

# Define the maximum axial slice dimensions for each tumor type
max_axial_slice_dimensions = {
    'HCC': (180, 233),
    'ICC': (180, 233),
    'MCRC': (180, 233)
}

def apply_window_level(ct_slice, window_level, window_width):
    lower_limit = window_level - window_width / 2
    upper_limit = window_level + window_width / 2

    # Create a mask for non-zero pixels
    non_zero_mask = ct_slice != 0

    # Clip the pixel values of the input array using the mask
    ct_slice[non_zero_mask] = np.clip(ct_slice[non_zero_mask], lower_limit, upper_limit)

    # Normalize the adjusted pixel values to the range [0, 1] using the mask
    ct_slice[non_zero_mask] = (ct_slice[non_zero_mask] - lower_limit) / (upper_limit - lower_limit)

    return ct_slice

def get_largest_tumor_slices(label_arr, n_slices=15, min_area=50):
    labeled_tumors = skimage_label(label_arr == 2)
    tumor_regions = regionprops(labeled_tumors)
    num_slices = label_arr.shape[2]

    # Include only slices where the tumor area is at least 50 pixels
    tumor_areas = [(z, np.sum(np.where(label_arr[:, :, z] == 2, 1, 0))) for z in range(num_slices) if np.sum(np.where(label_arr[:, :, z] == 2, 1, 0)) >= min_area]

    largest_tumor_slices = heapq.nlargest(n_slices, tumor_areas, key=lambda x: x[1])
    return [z for z, area in largest_tumor_slices]

def crop_image(ct_slice, label_slice, tumor_type):
    tumor_mask = label_slice == 2
    non_zero_indices = np.where(tumor_mask)

    if len(non_zero_indices[0]) == 0:
        return np.zeros_like(ct_slice), np.zeros_like(label_slice)

    tumor_center = np.mean(non_zero_indices, axis=1)
    max_axial_slice_dimensions_tumor_type = np.array(max_axial_slice_dimensions[tumor_type])
    half_lengths = max_axial_slice_dimensions_tumor_type / 2
    min_indices = np.round(tumor_center - half_lengths).astype(int)
    max_indices = np.round(tumor_center + half_lengths).astype(int)

    cropped_ct_slice = ct_slice[min_indices[0]:max_indices[0], min_indices[1]:max_indices[1]]
    cropped_label_slice = label_slice[min_indices[0]:max_indices[0], min_indices[1]:max_indices[1]]

    return cropped_ct_slice, cropped_label_slice

def process_largest_tumor_slice(ct_slice, label_slice, largest_tumor_slices, tumor_type, original_file_name, output_dir):
    for largest_tumor_slice in largest_tumor_slices:
        if largest_tumor_slice is not None:
            ct_slice_slice = ct_slice[:, :, largest_tumor_slice]
            label_slice_slice = label_slice[:, :, largest_tumor_slice]
            cropped_ct_slice, cropped_label_slice = crop_image(ct_slice_slice, label_slice_slice, tumor_type)
            ct_slice_tumor_only = np.where(cropped_label_slice == 2, cropped_ct_slice, 0)
            L = 40
            W = 350
            adjusted_ct_slice_tumor_only = apply_window_level(ct_slice_tumor_only, L, W)

            if np.any(adjusted_ct_slice_tumor_only):
                resized_ct_slice = resize(adjusted_ct_slice_tumor_only, (299, 299), anti_aliasing=True)
                rotated_ct_slice = np.rot90(resized_ct_slice, k=-1)
                adjusted_ct_slice_rgb = np.stack((rotated_ct_slice,) * 3, axis=-1)
                output_filename = f"{tumor_type}_{original_file_name}_slice{largest_tumor_slice}.png"
                output_path = os.path.join(output_dir, output_filename)
                print(f"Saving image to {output_path}")
                cv2.imwrite(output_path, (adjusted_ct_slice_rgb * 255).astype(np.uint8), [cv2.IMWRITE_PNG_COMPRESSION, 0])


            else:
                print(f"Skipping image {image_path} due to empty image.")

def process_image(image_file, label_file, tumor_type, output_dir):
    ct_slice_nifti = nib.load(image_file)
    label_slice_nifti = nib.load(label_file)
    ct_slice = ct_slice_nifti.get_fdata()
    label_slice = label_slice_nifti.get_fdata()

    largest_tumor_slices = get_largest_tumor_slices(label_slice)
    original_file_name = os.path.splitext(os.path.basename(image_file))[0]
    num_slices = ct_slice.shape[2]
    print(f"{tumor_type} - {original_file_name}: Largest Tumor Slices = {largest_tumor_slices}, Total Slices = {num_slices}")

    # Replace the loop with a function call
    process_largest_tumor_slice(ct_slice, label_slice, largest_tumor_slices, tumor_type, original_file_name, output_dir)

if not os.path.exists(output_dir):
    os.makedirs(output_dir)

for tumor_type in image_paths.keys():
    image_path = image_paths[tumor_type]
    label_path = label_paths[tumor_type]

    # Get image and label file names
    image_files = sorted(os.listdir(image_path), key=lambda x: int(re.findall(r'\d+', x)[0]))
    label_files = sorted(os.listdir(label_path), key=lambda x: int(re.findall(r'\d+', x)[0]))
    image_labels = [(os.path.join(image_path, img), os.path.join(label_path, lbl)) for img, lbl in zip(image_files, label_files)]

    # Split image_labels into training and validation sets
    train_image_labels, val_image_labels = train_test_split(image_labels, test_size=0.2, random_state=42)

    # Process training images
    for data_type, image_labels in zip(['train', 'val'], [train_image_labels, val_image_labels]):
        output_dir = output_dirs[tumor_type][data_type]

        if not os.path.exists(output_dir):
            os.makedirs(output_dir)

        for image_file, label_file in tqdm(image_labels, desc=f"{tumor_type} - {data_type.capitalize()}"):
            process_image(image_file, label_file, tumor_type, output_dir)

!pip install tensorflow-gpu==2.5.0

"""### Creating Datasets"""

import os
import numpy as np
import tensorflow as tf
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import RandomOverSampler

# Load dataset
print("Loading dataset...")
data_dir = "/mnt/largedrive0/rmojtahedi/liver_classifcation/Updated_Tumor_Slices"
class_names = ['HCC', 'ICC', 'MCRC']
image_size = (299, 299)

batch_size = 128
NUM_CLASSES = 3
IMG_SIZE = 299

output_dir = os.path.join(data_dir)

import re

def extract_image_ids(image_paths, class_name):
    unique_image_ids = set()
    if class_name == 'HCC':
        regex = r"{}_([a-zA-Z0-9]+)-".format(class_name)
    elif class_name == 'ICC':
        regex = r"{}_([a-zA-Z0-9]+)_".format(class_name)
    else:  # class_name is 'MCRC'
        regex = r"{}_mcrc_([a-zA-Z0-9]+)_".format(class_name)

    for image_path in image_paths:
        image_id = re.search(regex, image_path)
        if image_id is not None:
            unique_image_ids.add(image_id.group(1))  # Now this should be back to group(1)

    return len(unique_image_ids)


output_dirs = {
    'HCC': {
        'train': os.path.join(output_dir, 'HCC', 'train'),
        'val': os.path.join(output_dir, 'HCC', 'val')
    },
    'ICC': {
        'train': os.path.join(output_dir, 'ICC', 'train'),
        'val': os.path.join(output_dir, 'ICC', 'val')
    },
    'MCRC': {
        'train': os.path.join(output_dir, 'MCRC', 'train'),
        'val': os.path.join(output_dir, 'MCRC', 'val')
    }
}

def parse_image(image_path, label):
    # Load the raw data from the file as a string
    img = tf.io.read_file(image_path)

    # Decode the image data to a uint8 tensor
    img = tf.image.decode_png(img, channels=3)
    return img, label

def load_data(data_dir, class_names, image_size, phase):
    image_paths = []
    labels = []
    class_counts = {class_name: 0 for class_name in class_names}
    unique_image_counts = {class_name: 0 for class_name in class_names}

    for i, class_name in enumerate(class_names):
        class_dir = os.path.join(data_dir, output_dirs[class_name][phase])
        image_names = os.listdir(class_dir)
        class_image_paths = [os.path.join(class_dir, image_name) for image_name in image_names]
        image_paths.extend(class_image_paths)
        class_counts[class_name] += len(image_names)
        unique_image_counts[class_name] += extract_image_ids(class_image_paths, class_name)
        labels.extend([i] * len(image_names))

    # Print the count for each category before shuffling
    print(f"Category Counts for {phase} before shuffling:")
    for class_name in class_names:
        print(f"{class_name}: {class_counts[class_name]}")
        print(f"Unique {class_name} images: {unique_image_counts[class_name]}")

    image_paths = np.array(image_paths)
    labels = np.array(labels)

    return image_paths, labels, unique_image_counts


train_image_paths, train_labels, train_unique_image_counts = load_data(data_dir, class_names, image_size, 'train')
val_image_paths, val_labels, val_unique_image_counts = load_data(data_dir, class_names, image_size, 'val')

# Oversampling
# ros = RandomOverSampler(random_state=42)
# train_paths, train_labels = ros.fit_resample(np.array(train_image_paths).reshape(-1, 1), train_labels)
# val_paths, val_labels = ros.fit_resample(np.array(val_image_paths).reshape(-1, 1), val_labels)
# train_paths = train_paths.ravel()
# val_paths = val_paths.ravel()

# # Recalculate unique image counts after oversampling
# train_unique_image_counts = {class_name: extract_image_ids(train_paths[train_labels == i], class_name) for i, class_name in enumerate(class_names)}
# val_unique_image_counts = {class_name: extract_image_ids(val_paths[val_labels == i], class_name) for i, class_name in enumerate(class_names)}

print("Unique image counts after oversampling:")
print("Training set:")
for class_name in class_names:
    print(f"{class_name}: {train_unique_image_counts[class_name]}")
print("Validation set:")
for class_name in class_names:
    print(f"{class_name}: {val_unique_image_counts[class_name]}")


# One-hot encoding
train_labels = tf.keras.utils.to_categorical(train_labels, num_classes=len(class_names))
val_labels = tf.keras.utils.to_categorical(val_labels, num_classes=len(class_names))

def load_and_preprocess_image(image_path, label):
    image = tf.io.read_file(image_path)
    image = tf.image.decode_png(image, channels=3)
    image = tf.image.resize(image, image_size)

    # Apply min-max normalization
    min_val = tf.math.reduce_min(image)
    max_val = tf.math.reduce_max(image)
    norm_image = (image - min_val) * (255 / (max_val - min_val))

    # Clip the pixel values to be within [0, 255]
    norm_image = tf.clip_by_value(norm_image, 0, 255)

    return norm_image, label


def augment_image(image):
    image = tf.image.random_flip_left_right(image)  # Horizontal flip
    image = tf.image.random_flip_up_down(image)  # Vertical flip
    image = tf.image.random_brightness(image, max_delta=0.2)
    image = tf.image.random_contrast(image, lower=0.8, upper=1.2)
    image = tf.keras.preprocessing.image.random_rotation(image, 20)  # Random rotation

    # Ensure the output image has the exact same size as the input image
    image = tf.image.resize(image, image_size)  # Add this line

    return image


def augment_image_wrapper(image, label):
    image = tf.py_function(augment_image, [image], tf.float32)
    # print("Image shape:", image.shape)
    return image, label

train_ds = tf.data.Dataset.from_tensor_slices((train_image_paths, train_labels)) # use train_image_paths instead of train_paths
train_ds = train_ds.shuffle(buffer_size=len(train_image_paths))  # Moved up
train_ds = train_ds.map(load_and_preprocess_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)
train_ds = train_ds.map(augment_image_wrapper, num_parallel_calls=tf.data.experimental.AUTOTUNE)
train_ds = train_ds.batch(batch_size).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)

val_ds = tf.data.Dataset.from_tensor_slices((val_image_paths, val_labels)) # use val_image_paths instead of val_paths
val_ds = val_ds.map(parse_image, num_parallel_calls=tf.data.AUTOTUNE)
val_ds = val_ds.batch(batch_size)
val_ds = val_ds.prefetch(tf.data.AUTOTUNE)

import os
import re
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.utils import shuffle
import numpy as np
from imblearn.over_sampling import RandomOverSampler
import matplotlib.pyplot as plt


# Load dataset
print("Loading dataset...")
data_dir = "/mnt/largedrive0/rmojtahedi/liver_classifcation/Main_Tumour_Images"
class_names = ['HCC', 'ICC', 'MCRC']
image_size = (299, 299)
class_to_label = {'HCC': 0, 'ICC': 1, 'MCRC': 2}  # Added mapping
batch_size = 64
NUM_CLASSES = 3
IMG_SIZE = 299

def get_patient_id(image_path, class_name):
    if class_name == 'HCC':
        patient_id = re.findall('HCC_(.*?)-', image_path.split('/')[-1])[0]
    elif class_name == 'ICC':
        patient_id = re.findall('ICC_(.*?)_', image_path.split('/')[-1])[0]
    else:  # MCRC
        patient_id = re.findall('MCRC_mcrc_(.*?)_', image_path.split('/')[-1])[0]
    return patient_id

def load_data(data_dir, class_names):
    image_paths = []
    labels = []
    classes = []

    for class_name in class_names:
        class_dir = os.path.join(data_dir, class_name)
        image_names = os.listdir(class_dir)
        class_image_paths = [os.path.join(class_dir, image_name) for image_name in image_names]
        image_paths.extend(class_image_paths)
        labels.extend([class_to_label[class_name]] * len(image_names))
        classes.extend([class_name] * len(image_names))

    return image_paths, labels, classes

image_paths, labels, classes = load_data(data_dir, class_names)

# Group images, labels, and class names by patient ID
patient_dict = {}
for image_path, label, class_name in zip(image_paths, labels, classes):
    patient_id = get_patient_id(image_path, class_name)
    if patient_id not in patient_dict:
        patient_dict[patient_id] = {'image_paths': [], 'labels': [], 'classes': []}
    patient_dict[patient_id]['image_paths'].append(image_path)
    patient_dict[patient_id]['labels'].append(label)
    patient_dict[patient_id]['classes'].append(class_name)

# Prepare a list of patient_ids
patient_ids = list(patient_dict.keys())

# Split patients into train and validation sets
train_patient_ids, val_patient_ids = train_test_split(patient_ids, test_size=0.2, random_state=42)

# Split each patient's data into training and validation sets
train_image_paths, val_image_paths = [], []
train_labels, val_labels = [], []

for patient_id in train_patient_ids:
    train_image_paths.extend(patient_dict[patient_id]['image_paths'])
    train_labels.extend(patient_dict[patient_id]['labels'])

for patient_id in val_patient_ids:
    val_image_paths.extend(patient_dict[patient_id]['image_paths'])
    val_labels.extend(patient_dict[patient_id]['labels'])

# Counting the number of images per class before oversampling
image_count_before = {class_name: 0 for class_name in class_names}
for label in train_labels:
    class_name = list(class_to_label.keys())[list(class_to_label.values()).index(label)]
    image_count_before[class_name] += 1

print("\nImage counts in the training set before oversampling:")
print(image_count_before)

# Oversampling
ros = RandomOverSampler(random_state=42)
train_paths, train_labels = ros.fit_resample(np.array(train_image_paths).reshape(-1, 1), train_labels)
train_paths = train_paths.ravel()

# Counting the number of images per class after oversampling
image_count_after = {class_name: 0 for class_name in class_names}
for label in train_labels:
    class_name = list(class_to_label.keys())[list(class_to_label.values()).index(label)]
    image_count_after[class_name] += 1

print("\nImage counts in the training set after oversampling:")
print(image_count_after)

# One-hot encoding
train_labels = tf.keras.utils.to_categorical(train_labels, num_classes=NUM_CLASSES)
val_labels = tf.keras.utils.to_categorical(val_labels, num_classes=NUM_CLASSES)


# Now let's move on to defining the functions needed for data preprocessing and augmentation

def load_and_preprocess_image(image_path, label):
    image = tf.io.read_file(image_path)
    image = tf.image.decode_png(image, channels=3)
    image = tf.image.resize(image, image_size)

    # apply normalization here, after resizing
    min_val = tf.math.reduce_min(image)
    max_val = tf.math.reduce_max(image)
    image = (image - min_val) / (max_val - min_val)

    return image, label

def augment_image(image):
    image = tf.image.random_flip_left_right(image)  # Horizontal flip
    image = tf.image.random_flip_up_down(image)  # Vertical flip
    image = tf.image.random_brightness(image, max_delta=0.2)
    image = tf.image.random_contrast(image, lower=0.8, upper=1.2)

    # Random rotation
    image = tf.image.rot90(
        image,
        tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32)
    )

    image = tf.image.resize(image, image_size)  # Add this line

    return image

def augment_image_wrapper(image, label):
    image = tf.py_function(augment_image, [image], tf.float32)
    return image, label

# Create training and validation datasets
train_ds = tf.data.Dataset.from_tensor_slices((train_paths, train_labels))
train_ds = train_ds.shuffle(buffer_size=len(train_paths))
train_ds = train_ds.map(load_and_preprocess_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)
train_ds = train_ds.map(augment_image_wrapper, num_parallel_calls=tf.data.experimental.AUTOTUNE)
train_ds = train_ds.batch(batch_size).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)

val_ds = tf.data.Dataset.from_tensor_slices((val_image_paths, val_labels))
val_ds = val_ds.map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)
val_ds = val_ds.batch(batch_size)
val_ds = val_ds.prefetch(tf.data.AUTOTUNE)


class_images = {}  # to store a few images of each class
samples_per_class = 5  # we want to visualize 5 images per class

# as we iterate over the training data, we'll populate class_images
for images, labels in train_ds.take(samples_per_class * len(class_names)):
    for image, label in zip(images, labels):
        class_idx = tf.argmax(label).numpy()
        if class_names[class_idx] not in class_images:
            class_images[class_names[class_idx]] = [image]
        elif len(class_images[class_names[class_idx]]) < samples_per_class:
            class_images[class_names[class_idx]].append(image)

# now class_images contains 5 images for each class, let's visualize them
plt.figure(figsize=(10, 10))
for i, class_name in enumerate(class_names):
    for j in range(samples_per_class):
        plt.subplot(len(class_names), samples_per_class, i*samples_per_class + j + 1)
        plt.xticks([])
        plt.yticks([])
        plt.grid(False)
        plt.imshow(class_images[class_name][j])
        if j == 0:
            plt.title(class_name)
plt.show()

# Replace the unique patient count function to handle the modified data structure
def count_unique_patients(patient_dict, val_patient_ids, class_to_label):
    unique_patients = {class_name: set() for class_name in class_to_label.keys()}
    for patient_id in val_patient_ids:
        patient_class_names = patient_dict[patient_id]['classes']
        for class_name in patient_class_names:
            unique_patients[class_name].add(patient_id)
    return {k: len(v) for k, v in unique_patients.items()}

def count_images(image_paths):
    image_counts = {class_name: 0 for class_name in class_names}
    for image_path in image_paths:
        class_name = os.path.basename(os.path.dirname(image_path))
        image_counts[class_name] += 1
    return image_counts

# Count unique patients in training and validation sets
train_patient_counts = count_unique_patients(patient_dict, train_patient_ids, class_to_label)
val_patient_counts = count_unique_patients(patient_dict, val_patient_ids, class_to_label)

# Count images in training and validation sets
train_image_counts = count_images(train_image_paths)
val_image_counts = count_images(val_image_paths)

# Print the counts
print("Unique patient counts in the training set:")
print(train_patient_counts)

print("\nUnique patient counts in the validation set:")
print(val_patient_counts)

print("\nImage counts in the training set:")
print(train_image_counts)

print("\nImage counts in the validation set:")
print(val_image_counts)

"""### Training Networks"""

from tensorflow.keras.models import Model
from tensorflow.keras import layers
from tensorflow.keras.layers import BatchNormalization, Dense, GlobalAveragePooling2D
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from tensorflow.keras.applications import InceptionV3, Xception, ResNet152V2
import tensorflow as tf
from tensorflow.keras.optimizers import Adam
from tensorflow.keras import regularizers
import os
from sklearn.metrics import f1_score, recall_score, precision_score

class CustomCallback(tf.keras.callbacks.Callback):
    def __init__(self, model_name):
        super(CustomCallback, self).__init__()
        self.model_name = model_name
        self.best_val_accuracy = 0.0
        self.best_metrics = None

    def on_epoch_end(self, epoch, logs=None):
        val_labels = []
        val_predictions = []

        for x, y in val_ds:
            predictions = self.model.predict(x)
            val_predictions.extend(predictions.argmax(axis=1))
            val_labels.extend(y.numpy().argmax(axis=1))

        val_accuracy = logs['val_accuracy']
        _val_f1 = f1_score(val_labels, val_predictions, average='macro')
        _val_recall = recall_score(val_labels, val_predictions, average='macro')
        _val_precision = precision_score(val_labels, val_predictions, average='macro')

        if val_accuracy > self.best_val_accuracy:
            self.best_val_accuracy = val_accuracy
            self.best_metrics = {
                'val_f1': _val_f1,
                'val_precision': _val_precision,
                'val_recall': _val_recall
            }

    def on_train_end(self, logs=None):
        print(f"\nSummary of Highest Results:")
        for model_name, callback in callbacks.items():
            best_metrics = callback.best_metrics
            print(f"{model_name}:")
            print(f"  - Best validation accuracy: {callback.best_val_accuracy}")
            print(f"  - Best F1 score: {best_metrics['val_f1']}")
            print(f"  - Best precision: {best_metrics['val_precision']}")
            print(f"  - Best recall: {best_metrics['val_recall']}")

models = {
    'Xception': Xception,
    'InceptionV3': InceptionV3,
    'ResNet152V2': ResNet152V2
}

epochs = 30
IMG_SIZE = 299  # please specify your image size
callbacks = {}

for model_name, model_fn in models.items():
    print(f'Training {model_name}...')
    checkpoint_filepath = f"/mnt/largedrive0/rmojtahedi/liver_classification/MICCAI_BASELINE/{model_name}_baseline.h5"

    inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))
    base_model = model_fn(include_top=False, input_tensor=inputs, weights="imagenet")

    for layer in base_model.layers:
        layer.trainable = False

    x = layers.GlobalAveragePooling2D(name="avg_pool")(base_model.output)
    x = layers.BatchNormalization()(x)

    x = layers.Dense(1024, activation='relu', name='dense_90')(x)
    x = layers.BatchNormalization()(x)
    x = layers.Dense(128, activation='relu', name='dense_91')(x)
    x = layers.BatchNormalization()(x)

    predictions = layers.Dense(3, activation='softmax', kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4))(x)

    model = Model(inputs=base_model.input, outputs=predictions)

    for layer in model.layers:
        if isinstance(layer, layers.Dense):
            layer.trainable = True
        else:
            layer.trainable = False

    model.compile(
        optimizer=Adam(learning_rate=0.0001),
        loss=tf.keras.losses.CategoricalCrossentropy(),
        metrics=["accuracy"]
    )

    if os.path.exists(checkpoint_filepath):
        os.remove(checkpoint_filepath)

    checkpoint_callback = ModelCheckpoint(
        filepath=checkpoint_filepath,
        monitor="val_accuracy",
        mode="max",
        save_best_only=True,
        verbose=1,
    )

    early_stopping_callback = EarlyStopping(
        monitor="val_accuracy",
        mode="max",
        patience=10,
        verbose=1,
    )

    custom_callback = CustomCallback(model_name)
    callbacks[model_name] = custom_callback

    history = model.fit(
        train_ds,
        epochs=epochs,
        validation_data=val_ds,
        verbose=2,
        callbacks=[checkpoint_callback, early_stopping_callback, custom_callback],
    )

print('\n')

"""### Contrastive Learning"""

import tensorflow as tf
from tensorflow.keras import layers, regularizers
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.losses import MeanSquaredError
import os
import math
from tensorflow.keras.applications import InceptionV3, Xception, ResNet152V2
import numpy as np


from tensorflow.keras.mixed_precision import experimental as mixed_precision
policy = mixed_precision.Policy('mixed_float16')
mixed_precision.set_policy(policy)

import tensorflow as tf
gpus = tf.config.experimental.list_physical_devices('GPU')
if gpus:
    try:
        for gpu in gpus:
            tf.config.experimental.set_memory_growth(gpu, True)
    except RuntimeError as e:
        print(e)


# Constants
image_size = (299, 299)
os.environ["CUDA_VISIBLE_DEVICES"] = "0"

PROJECT_DIM = 1024
LATENT_DIM = 2048
WEIGHT_DECAY = 1e-4
BATCH_SIZE = 64
EPOCHS = 100
patience_con = 100

# Assume you've defined train_paths and val_paths
# Combine all paths
all_image_paths = np.concatenate((train_image_paths, val_image_paths))

# Convert to tf.data.Dataset
all_ds = tf.data.Dataset.from_tensor_slices(all_image_paths)

# Define augment function
def custom_augment(image_path):
    img = tf.io.read_file(image_path)
    img = tf.image.decode_png(img, channels=3)
    img = tf.image.resize(img, image_size)

    # Apply augmentation here
    img = tf.image.random_flip_left_right(img)
    img = tf.image.random_flip_up_down(img)
    img = tf.image.random_brightness(img, max_delta=0.2)
    img = tf.image.random_contrast(img, lower=0.8, upper=1.2)

    return img

# Prepare two versions of dataset with different augmentations
ssl_ds_one = all_ds.map(custom_augment, num_parallel_calls=tf.data.AUTOTUNE)
ssl_ds_two = all_ds.map(custom_augment, num_parallel_calls=tf.data.AUTOTUNE)

# We only take the images (ignore labels) and apply augmentations
ssl_ds_one = ssl_ds_one.map(lambda img: img).batch(BATCH_SIZE)
ssl_ds_two = ssl_ds_two.map(lambda img: img).batch(BATCH_SIZE)

# Zip both datasets
ssl_ds_train = tf.data.Dataset.zip((ssl_ds_one, ssl_ds_two))
ssl_ds_train = ssl_ds_train.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)

# Define Encoder (with InceptionV3 as base)
def get_encoder(base_model_name):
    if base_model_name == 'InceptionV3':
        base_model = InceptionV3(weights="imagenet", include_top=False, input_shape=(*image_size, 3))
    elif base_model_name == 'Xception':
        base_model = Xception(weights="imagenet", include_top=False, input_shape=(*image_size, 3))
    elif base_model_name == 'ResNet152V2':
        base_model = ResNet152V2(weights="imagenet", include_top=False, input_shape=(*image_size, 3))
    else:
        raise ValueError(f"Invalid {base_model_name}")

    base_model.trainable = False

    inputs = base_model.input
    x = base_model.output
    x = layers.GlobalAveragePooling2D(name="avg_pool")(x)
    x = layers.BatchNormalization()(x)
    x = layers.Dense(1024, activation='relu', name="dense_90")(x)
    x = layers.BatchNormalization()(x)
    x = layers.Dense(128, activation='relu', name="dense_91")(x)
    x = layers.BatchNormalization()(x)

    outputs = x
    return Model(inputs, outputs, name="encoder")

# Define Predictor
def get_predictor():
    model = tf.keras.Sequential([
        layers.Input((128,)),
        layers.Dense(PROJECT_DIM, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4)),
        layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4)),
    ], name="predictor")
    return model

# Define Loss
def compute_loss_cosine(p, z):
    z = tf.stop_gradient(z)
    p = tf.math.l2_normalize(p, axis=1)
    z = tf.math.l2_normalize(z, axis=1)
    return -tf.reduce_mean(tf.reduce_sum((p * z), axis=1))

def compute_loss_mse(p, z):
    mse = MeanSquaredError()
    return mse(p, z)

# Define SimSiam Model
class SimSiam(Model):
    def __init__(self, encoder, predictor):
        super(SimSiam, self).__init__()
        self.encoder = encoder
        self.predictor = predictor
        self.loss_tracker_cosine = tf.keras.metrics.Mean(name="loss_cosine")
        self.loss_tracker_mse = tf.keras.metrics.Mean(name="loss_mse")

    @property
    def metrics(self):
        return [self.loss_tracker_cosine, self.loss_tracker_mse]

    def call(self, inputs):
        z = self.encoder(inputs)
        p = self.predictor(z)
        return p, z

    def train_step(self, data):
        ds_one, ds_two = data

        with tf.GradientTape() as tape:
            p1, z1 = self.__call__(ds_one)
            p2, z2 = self.__call__(ds_two)

            loss_cosine = compute_loss_cosine(p1, z2) / 2 + compute_loss_cosine(p2, z1) / 2
            loss_mse = compute_loss_mse(p1, z2) / 2 + compute_loss_mse(p2, z1) / 2
            loss = loss_cosine + loss_mse

        learnable_params = self.encoder.trainable_variables + self.predictor.trainable_variables
        gradients = tape.gradient(loss, learnable_params)
        self.optimizer.apply_gradients(zip(gradients, learnable_params))

        self.loss_tracker_cosine.update_state(loss_cosine)
        self.loss_tracker_mse.update_state(loss_mse)
        return {"loss_cosine": self.loss_tracker_cosine.result(), "loss_mse": self.loss_tracker_mse.result()}

# Prepare for training
lr_decayed_fn = tf.keras.optimizers.schedules.CosineDecay(
    initial_learning_rate=0.0001, decay_steps=EPOCHS
)

# base_model_list = ['InceptionV3', 'Xception', 'ResNet152V2']
base_model_list = ['ResNet152V2']

for base_model_name in base_model_list:
    # Get encoder
    encoder = get_encoder(base_model_name)

    # Prepare SimSiam model
    simsiam = SimSiam(encoder, get_predictor())
    simsiam.build((None, *image_size, 3))  # Creates the weights of the model
    simsiam.compile(optimizer=Adam(lr_decayed_fn))  # Configures the model for training

    best_cosine_loss = float('inf')
    best_mse_loss = float('inf')
    counter_cosine = 0
    counter_mse = 0

    print(f"Training with {base_model_name}")

    for epoch in range(EPOCHS):
        print("Start of epoch %d" % (epoch,))
        for data in ssl_ds_train:
            result = simsiam.train_step(data)
            current_cosine_loss = result['loss_cosine'].numpy()
            current_mse_loss = result['loss_mse'].numpy()

            print(f"Current Cosine Loss: {current_cosine_loss}, Current MSE Loss: {current_mse_loss}")

            dense_model = Model(inputs=simsiam.encoder.input, outputs=simsiam.encoder.get_layer('dense_91').output)

            if current_cosine_loss < best_cosine_loss:
                best_cosine_loss = current_cosine_loss
                simsiam.encoder.save(f'/mnt/largedrive0/rmojtahedi/liver_classifcation/MICCAI_PRETRAINED/{base_model_name}_SimSiam_encoder_cosine.h5')
                dense_model.save(f'/mnt/largedrive0/rmojtahedi/liver_classifcation/MICCAI_PRETRAINED/{base_model_name}_SimSiam_weights_cosine.h5')
                counter_cosine = 0
                print(f"Cosine Loss improved to {best_cosine_loss}. Saving model.")
            else:
                counter_cosine += 1

            if current_mse_loss < best_mse_loss:
                best_mse_loss = current_mse_loss
                simsiam.encoder.save(f'/mnt/largedrive0/rmojtahedi/liver_classifcation/MICCAI_PRETRAINED/{base_model_name}_SimSiam_encoder_mse.h5')
                dense_model.save(f'/mnt/largedrive0/rmojtahedi/liver_classifcation/MICCAI_PRETRAINED/{base_model_name}_SimSiam_weights_mse.h5')
                counter_mse = 0
                print(f"MSE Loss improved to {best_mse_loss}. Saving model.")
            else:
                counter_mse += 1

            if counter_cosine > patience_con or counter_mse > patience_con:
                print("Early stopping due to not improving loss.")
                break

        # Reset loss trackers at the end of each epoch
        simsiam.loss_tracker_cosine.reset_states()
        simsiam.loss_tracker_mse.reset_states()

        if counter_cosine > patience_con or counter_mse > patience_con:
            break

"""### Fine-tuning"""

from tensorflow.keras.models import Model, load_model
from tensorflow.keras.applications import InceptionV3, Xception, ResNet152V2
from tensorflow.keras import layers
from tensorflow.keras.optimizers import Adam
from tensorflow.keras import regularizers
import tensorflow as tf
import os
from sklearn.metrics import f1_score, recall_score, precision_score
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint

callbacks = {}

class CustomCallback(tf.keras.callbacks.Callback):
    def __init__(self, model_name):
        super(CustomCallback, self).__init__()
        self.model_name = model_name
        self.best_val_accuracy = 0.0
        self.best_metrics = None

    def on_epoch_end(self, epoch, logs=None):
        val_labels = []
        val_predictions = []

        for x, y in val_ds:
            predictions = self.model.predict(x)
            val_predictions.extend(predictions.argmax(axis=1))
            val_labels.extend(y.numpy().argmax(axis=1))

        val_accuracy = logs['val_accuracy']
        _val_f1 = f1_score(val_labels, val_predictions, average='macro')
        _val_recall = recall_score(val_labels, val_predictions, average='macro')
        _val_precision = precision_score(val_labels, val_predictions, average='macro')

        if val_accuracy > self.best_val_accuracy:
            self.best_val_accuracy = val_accuracy
            self.best_metrics = {
                'val_f1': _val_f1,
                'val_precision': _val_precision,
                'val_recall': _val_recall
            }

    def on_train_end(self, logs=None):
        print(f"\nSummary of Highest Results:")
        for model_name, callback in callbacks.items():
            best_metrics = callback.best_metrics
            print(f"{model_name}:")
            print(f"  - Best validation accuracy: {callback.best_val_accuracy}")
            print(f"  - Best F1 score: {best_metrics['val_f1']}")
            print(f"  - Best precision: {best_metrics['val_precision']}")
            print(f"  - Best recall: {best_metrics['val_recall']}")

def train_model(model_name, model_fn, encoder_weights_path):
    IMG_SIZE = 299  # please specify your image size
    epochs = 100
    PATIENCE = 30

    encoder_weights_path = os.path.join('/mnt/largedrive0/rmojtahedi/liver_classifcation/MICCAI_PRETRAINED', f'{model_name}_SimSiam_encoder_{loss}.h5')


    inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))
    base_model = model_fn(include_top=False, input_tensor=inputs, weights="imagenet")

    # Freeze the base model
    base_model.trainable = False

    x = layers.GlobalAveragePooling2D(name="avg_pool")(base_model.output)
    x = layers.BatchNormalization()(x)
    x = layers.Dense(1024, activation='relu', name='dense_90')(x)
    x = layers.BatchNormalization()(x)
    x = layers.Dense(128, activation='relu', name='dense_91')(x)
    x = layers.BatchNormalization()(x)
    predictions = layers.Dense(3, activation='softmax', kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4), name="dense_92")(x)

    model = Model(inputs=base_model.input, outputs=predictions)

    # Load the weights from self-supervised training into the dense layers
    model.load_weights(encoder_weights_path, by_name=True)

    # Set only the specified dense layers as trainable
    for layer in model.layers:
        if layer.name in ['dense_90', 'dense_91', 'dense_92']:
            layer.trainable = True
        else:
            layer.trainable = False

    model.compile(
        optimizer=Adam(learning_rate=0.0001),
        loss=tf.keras.losses.CategoricalCrossentropy(),
        metrics=["accuracy"]
    )

    checkpoint_filepath = "/mnt/largedrive0/rmojtahedi/liver_classifcation/MICCAI_PRETRAINED"

    checkpoint_callback = ModelCheckpoint(
        filepath=checkpoint_filepath,
        monitor="val_accuracy",
        mode="max",
        save_best_only=True,
        verbose=1,
    )

    early_stopping_callback = EarlyStopping(
        monitor="val_accuracy",
        mode="max",
        patience=30,
        verbose=1,
    )

    custom_callback = CustomCallback(model_name)
    callbacks[model_name] = custom_callback

    history = model.fit(
        train_ds,
        epochs=epochs,
        validation_data=val_ds,
        verbose=2,
        callbacks=[checkpoint_callback, early_stopping_callback, custom_callback],
    )

    return history, model

models = {
    'InceptionV3': InceptionV3,
    'ResNet152V2': ResNet152V2,
    'Xception': Xception
}

losses = ['mse', 'cosine']
best_model, best_history, best_accuracy = None, None, 0.0

for model_name, model_fn in models.items():
    for loss in losses:
        encoder_weights_path = os.path.join('/mnt/largedrive0/rmojtahedi/liver_classifcation/MICCAI_PRETRAINED', f'{model_name}_SimSiam_encoder_{loss}.h5')
        history, model = train_model(model_name, model_fn, loss)

        # Check if the current model has better validation accuracy
        if history.history['val_accuracy'][-1] > best_accuracy:
            best_accuracy = history.history['val_accuracy'][-1]
            best_model = model
            best_history = history

# print(f"Best Model: {best_model}")
# print(f"  - Final training accuracy: {best_history.history['accuracy'][-1]}")
# print(f"  - Final validation accuracy: {best_history.history['val_accuracy'][-1]}")
# print(f"  - Final training precision: {best_history.history['precision'][-1]}")
# print(f"  - Final validation precision: {best_history.history['val_precision'][-1]}")
# print(f"  - Final training recall: {best_history.history['recall'][-1]}")
# print(f"  - Final validation recall: {best_history.history['val_recall'][-1]}")
# print(f"  - Final training F1 score: {best_history.history['f1_score'][-1]}")
# print(f"  - Final validation F1 score: {best_history.history['val_f1_score'][-1]}")